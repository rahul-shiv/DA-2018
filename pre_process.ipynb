{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import plotly.offline as off\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.neighbors import  KNeighborsRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulshiv/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning:\n",
      "\n",
      "Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta = pd.read_csv('movies_metadata.csv')\n",
    "keywords = pd.read_csv('keywords.csv')\n",
    "ratings = pd.read_csv('ratings_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function does imputation for the passed columns using the given regressor\n",
    "def reg_fill(df, column, regressor):\n",
    "    ndf = df.dropna(subset=[col for col in df.columns if col != column])\n",
    "    ndf.loc[ndf[column]<5000,column]=None\n",
    "    nullmask = ndf[column].isnull()\n",
    "    train, test  = ndf[~nullmask], ndf[nullmask]\n",
    "    train_x, train_y = train.drop(column, axis=1), train[column]\n",
    "    regressor.fit(train_x, train_y)\n",
    "    if len(test) > 0:\n",
    "        test_x, test_y = test.drop(column, axis=1), test[column]\n",
    "        values = regressor.predict(test_x)\n",
    "        test_y = pd.Series(values)\n",
    "        test_y.index = test.index\n",
    "        new_x, new_y = pd.concat([train_x, test_x]), pd.concat([train_y, test_y])\n",
    "        return new_y\n",
    "    else:\n",
    "        return ndf[column]\n",
    "\n",
    "#this function counts occurences of words in the required column\n",
    "def count_word(df, ref_col, list_):\n",
    "    keyword_count = dict()\n",
    "    for s in list_: keyword_count[s] = 0\n",
    "    for list_keywords in df[ref_col]:        \n",
    "        if type(list_keywords) == float and pd.isnull(list_keywords): continue        \n",
    "        for s in [s for s in list_keywords if s in list_]: \n",
    "            if pd.notnull(s): keyword_count[s] += 1\n",
    "    # convert the dictionary in a list to sort the keywords by frequency\n",
    "    keyword_occurences = []\n",
    "    for k,v in keyword_count.items():\n",
    "        keyword_occurences.append([k,v])\n",
    "    keyword_occurences.sort(key = lambda x:x[1], reverse = True)\n",
    "    return keyword_occurences, keyword_count\n",
    "\n",
    "def convert(task):\n",
    "    temp_dict = dict()\n",
    "    temp_arr = []\n",
    "    temp_series = meta[task]\n",
    "    for item in temp_series:\n",
    "        if type(item) != type(str()):\n",
    "            continue\n",
    "        t = literal_eval(item)\n",
    "        if type(t)!=type([]):\n",
    "            continue\n",
    "        temp =[]\n",
    "        for i in t:\n",
    "            temp.append(i['name'])\n",
    "            if str(i['name']) not in temp_dict.keys():\n",
    "                temp_dict[str(i['name'])] = 1\n",
    "            else:\n",
    "                temp_dict[str(i['name'])]+=1\n",
    "        temp_arr.append(temp)\n",
    "    meta[task]=pd.Series(temp_arr)\n",
    "    return temp_dict\n",
    "\n",
    "def replacement_df_keywords(df, dict_repl, roots = False):\n",
    "    df_new = df.copy(deep = True)\n",
    "    for index, row in df_new.iterrows():\n",
    "        chain = row['keywords']\n",
    "        if type(chain) == type(0.0) : continue\n",
    "        temp = []\n",
    "        for s in chain: \n",
    "            key = PS.lemmatize(s) if roots else s\n",
    "            if key in dict_repl.keys():\n",
    "                temp.append(dict_repl[key])\n",
    "            else:\n",
    "                temp.append(s) if roots else temp.append(s)       \n",
    "        df_new.at[index, 'keywords'] = temp\n",
    "    return df_new\n",
    "\n",
    "def keywords_inventory(dataframe, column = 'keywords'):\n",
    "    keywords_roots  = dict()  # collect the words / root\n",
    "    keywords_select = dict()  # association: root <-> keyword\n",
    "    category_keys = []\n",
    "    icount = 0\n",
    "    for s in dataframe[column]:\n",
    "        if type(s) == type(0.0) : continue\n",
    "        for t in s:\n",
    "            t = t.lower()\n",
    "            root = PS.lemmatize(t)\n",
    "            if root in keywords_roots:    \n",
    "                 keywords_roots[root].add(t)\n",
    "            else:\n",
    "                keywords_roots[root]={t}\n",
    "    for s in keywords_roots.keys():\n",
    "        if len(keywords_roots[s]) > 1:  \n",
    "            min_length = 1000\n",
    "            for k in keywords_roots[s]:\n",
    "                if len(k) < min_length:\n",
    "                    key = k ; min_length = len(k)            \n",
    "            category_keys.append(key)\n",
    "            keywords_select[s] = key\n",
    "        else:\n",
    "            category_keys.append(list(keywords_roots[s])[0])\n",
    "            keywords_select[s] = list(keywords_roots[s])[0]\n",
    "                   \n",
    "    print(\"No of keywords in variable '{}': {}\".format(column,len(category_keys)))\n",
    "    return category_keys, keywords_roots, keywords_select\n",
    "\n",
    "\n",
    "def get_synonyms(word_key):\n",
    "    lemma = set()\n",
    "    for ss in wordnet.synsets(word_key):\n",
    "        for w in ss.lemma_names():\n",
    "            index = ss.name().find('.')+1\n",
    "            if ss.name()[index] == 'n': lemma.add(w.lower().replace('_',' '))\n",
    "    return lemma   \n",
    "\n",
    "def test_keyword(word, key_count, threshold):\n",
    "    return (False , True)[key_count.get(word, 0) >= threshold]\n",
    "\n",
    "def genre_transform():\n",
    "    temp_dict = dict()\n",
    "    for index,row in meta.iterrows():\n",
    "        movies_list.append(tuple([row.release_date.year,row.revenue]))\n",
    "        for i in row.genres:\n",
    "            if str(i) not in temp_dict.keys():\n",
    "                temp_dict[str(i)] = [tuple([row.release_date.year,row.revenue])]\n",
    "            else:\n",
    "                temp_dict[str(i)].append(tuple([row.release_date.year,row.revenue]))\n",
    "    return temp_dict\n",
    "\n",
    "def convert_key():\n",
    "    temp = \"\"\n",
    "    temp_series = df_keywords_synonyms['keywords']\n",
    "    for item in temp_series:\n",
    "        if type(item)!=type([]):\n",
    "            continue\n",
    "        for i in item:\n",
    "            temp = temp + i\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PS = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "off.init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "ratings = ratings.rename(columns={'movieId':'id'})\n",
    "#Convert IDs to numeric from string\n",
    "meta = meta[meta.status==\"Released\"]\n",
    "meta.id = pd.to_numeric(meta.id,errors=\"coerce\")\n",
    "meta.budget = pd.to_numeric(meta.budget,errors=\"coerce\")\n",
    "meta = meta.dropna(subset=[\"id\"])\n",
    "meta.loc[:,'release_date']=pd.to_datetime(meta.release_date, format = '%Y-%m-%d', errors=\"coerce\")\n",
    "meta = meta.dropna(subset=[\"release_date\"])\n",
    "meta = meta.drop_duplicates(subset=['id'])\n",
    "meta = meta.drop(['adult','belongs_to_collection','status','tagline','homepage','poster_path','production_countries','video','spoken_languages','original_title'], axis =1)\n",
    "\n",
    "keywords = keywords[keywords.keywords!=\"[]\"]\n",
    "keywords = keywords.drop_duplicates(subset=['id'])\n",
    "meta = pd.merge(meta,\n",
    "                 keywords,\n",
    "                 on='id',how='left')\n",
    "\n",
    "tab_info=pd.DataFrame(meta.dtypes).T.rename(index={0:'column type'})\n",
    "tab_info=tab_info.append(pd.DataFrame(meta.isnull().sum()).T.rename(index={0:'null values'}))\n",
    "tab_info=tab_info.append(pd.DataFrame(meta.isnull().sum()/meta.shape[0]*100).T.\n",
    "                         rename(index={0:'null values (%)'}))\n",
    "\n",
    "\n",
    "meta.popularity = pd.to_numeric(meta.popularity, errors='coerce')\n",
    "meta = meta.dropna(subset=[col for col in meta.columns[[0,5,8,9,11,12]]])\n",
    "tasks = ['genres','production_companies','keywords']\n",
    "\n",
    "impute_order = ['budget','revenue']\n",
    "for col in impute_order:\n",
    "    meta.loc[:,col] = reg_fill(meta.loc[:,['budget','popularity','revenue','runtime','vote_average','vote_count']], col,  KNeighborsRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of keywords in variable 'keywords': 19568\n"
     ]
    }
   ],
   "source": [
    "keyword_dict = convert('keywords')\n",
    "\n",
    "df_2 = meta\n",
    "\n",
    "icount = 0\n",
    "for index, row in meta[meta['keywords'].isnull()].iterrows():\n",
    "    icount += 1\n",
    "    word_list = row['title'].strip().split()\n",
    "    new_keyword = []\n",
    "    for s in word_list:\n",
    "        lemma = get_synonyms(s)\n",
    "        for t in list(lemma):\n",
    "            if t in keyword_dict.keys(): \n",
    "                new_keyword.append(t)\n",
    "    if new_keyword:\n",
    "        meta.at[index, 'keywords'] = new_keyword\n",
    "\n",
    "keywords_dat, keywords_roots, keywords_select = keywords_inventory(meta,\n",
    "                                                               column = 'keywords')\n",
    "\n",
    "df_keywords_cleaned = replacement_df_keywords(meta, keywords_select,\n",
    "                                               roots = True)\n",
    "\n",
    "keyword_occurences, keywords_count = count_word(df_keywords_cleaned,'keywords',keywords_dat)\n",
    "\n",
    "keyword_occurences.sort(key = lambda x:x[1], reverse = False)\n",
    "key_count = dict()\n",
    "for s in keyword_occurences:\n",
    "    key_count[s[0]] = s[1]\n",
    "\n",
    "repl_word = dict()\n",
    "icount = 0\n",
    "for index, [word, nb_apparitions] in enumerate(keyword_occurences):\n",
    "    if nb_apparitions > 5: continue  \n",
    "    lemma = get_synonyms(word)\n",
    "    if len(lemma) == 0: continue  \n",
    "    word_list = [(s, key_count[s]) for s in lemma \n",
    "                  if test_keyword(s, key_count, key_count[word])]\n",
    "    word_list.sort(key = lambda x:(x[1],x[0]), reverse = True)    \n",
    "    if len(word_list) <= 1: continue     \n",
    "    if word == word_list[0][0]: continue\n",
    "    repl_word[word] = word_list[0][0]\n",
    "\n",
    "for key, value in repl_word.items():\n",
    "    if value in repl_word.keys():\n",
    "        repl_word[key] = repl_word[value]  \n",
    "        \n",
    "df_keywords_synonyms = replacement_df_keywords(df_keywords_cleaned, repl_word, roots = False)   \n",
    "\n",
    "keywords_dat, keywords_roots, keywords_select = keywords_inventory(df_keywords_synonyms, column = 'keywords')\n",
    "\n",
    "new_keyword_occurences, keywords_count = count_word(df_keywords_synonyms,\n",
    "                                                    'keywords',keywords_dat)\n",
    "\n",
    "movies_list = []\n",
    "\n",
    "genre_plot_dict = genre_transform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta = df_keywords_synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating word cloud for title:\n",
    "meta['title'] = meta['title'].astype(str)\n",
    "title = ' '.join(meta['title'])\n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = set(STOPWORDS), \n",
    "                min_font_size = 10).generate(title)\n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store keyword_dict\n",
    "%store new_keyword_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating word cloud for keywords:\n",
    "string = convert_key()\n",
    "\n",
    "wordcloud_key = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = set(STOPWORDS), \n",
    "                min_font_size = 10).generate(string)\n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud_key) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta.to_csv(\"movies_metadata_preprocessed.csv\",sep=\",\",index=False)\n",
    "keywords.to_csv(\"keywords_preprocessed.csv\",sep=\",\",index=False)\n",
    "ratings.to_csv(\"ratings_preprocessed.csv\",sep=\",\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
